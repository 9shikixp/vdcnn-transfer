{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-11T14:01:10.535218Z",
     "start_time": "2018-01-11T14:01:10.500118Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-11T14:01:11.398743Z",
     "start_time": "2018-01-11T14:01:10.945788Z"
    }
   },
   "outputs": [],
   "source": [
    "import chainer\n",
    "import chainer.functions as F\n",
    "from chainer import function, initializers\n",
    "import chainer.links as L\n",
    "from chainer import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-11T14:01:11.479212Z",
     "start_time": "2018-01-11T14:01:11.401285Z"
    }
   },
   "outputs": [],
   "source": [
    "class KMaxPooling1D(function.Function):\n",
    "    \n",
    "    def __init__(self, ndim, k):\n",
    "        if ndim <= 0:\n",
    "            raise ValueError(\n",
    "                'pooling operation requires at least one spatial dimension.')\n",
    "\n",
    "        self.ndim = ndim\n",
    "        self.k = k\n",
    "\n",
    "        self._used_cudnn = False\n",
    "\n",
    "    def forward_gpu(self, x):\n",
    "        if chainer.should_use_cudnn('>=auto') and 2 <= self.ndim <= 3:\n",
    "            # With cuDNN v3 or greater, use cuDNN implementation for inputs\n",
    "            # with spatial dimensions of two or more.\n",
    "            return super(KMaxPooling1D, self).forward_gpu(x)\n",
    "\n",
    "        self.retain_inputs(())\n",
    "        self._in_shape = x[0].shape\n",
    "        self._in_dtype = x[0].dtype\n",
    "\n",
    "        n, c = x[0].shape[:2]\n",
    "        dims = x[0].shape[2:]\n",
    "        ys = (self.k,)\n",
    "\n",
    "        y_shape = (n, c) + ys\n",
    "        y = cuda.cupy.empty(y_shape, dtype=x[0].dtype)\n",
    "        self.indexes = cuda.cupy.empty(y_shape, dtype=np.int32)\n",
    "        \n",
    "        cuda.elementwise('raw T in, int32 d_0, int32 out_0',\n",
    "                         'T out, S indexes', \n",
    "                         '''int c0 = i / (out_0);\n",
    "                            int out_x_0 = i % out_0;\n",
    "                            int in_x0_0 = 0;\n",
    "                            int in_x1_0 = d_0;\n",
    "                            int argmax_0[''' + str(self.k) + '''];\n",
    "                            T maxval[''' + str(self.k) + '''];\n",
    "                            for (int a = 0; a < out_0; ++a) {\n",
    "                              maxval[a] = (T)-(1.0/0.0);\n",
    "                              argmax_0[a] = -1;\n",
    "                            }\n",
    "                            for (int a = 0; a < out_0; ++a) {\n",
    "                              for (int x_0 = in_x0_0; x_0 < in_x1_0; ++x_0) {\n",
    "                                int offset_0 = 1 * (x_0 + d_0 * c0);\n",
    "                                int found = 0;\n",
    "                                for (int b = 0; b < a; ++b) {\n",
    "                                  if (argmax_0[b] == x_0) {\n",
    "                                    found = 1;\n",
    "                                    break;\n",
    "                                  }\n",
    "                                }\n",
    "                                if (found) {\n",
    "                                  continue;\n",
    "                                }\n",
    "                                T v = in[offset_0];\n",
    "                                if (maxval[a] < v) {\n",
    "                                  maxval[a] = v;\n",
    "                                  argmax_0[a] = x_0;\n",
    "                                }\n",
    "                              }\n",
    "                            }\n",
    "                            for (int a = 0; a < out_0; ++a) {\n",
    "                              for (int b = a + 1; b < out_0; ++b) {\n",
    "                                if (argmax_0[a] > argmax_0[b]) {\n",
    "                                  T tmpval = maxval[a];\n",
    "                                  int tmpindex = argmax_0[a];\n",
    "                                  maxval[a] = maxval[b];\n",
    "                                  argmax_0[a] = argmax_0[b];\n",
    "                                  maxval[b] = tmpval;\n",
    "                                  argmax_0[b] = tmpindex;\n",
    "                                }\n",
    "                              }\n",
    "                            }\n",
    "                            out = maxval[i % out_0];\n",
    "                            int argmax_k_0 = argmax_0[i % out_0];\n",
    "                            indexes = argmax_k_0;\n",
    "                         ''',\n",
    "                         'k_max_pool_1d_fwd')(\n",
    "            x[0].reduced_view(),\n",
    "            *(dims + ys +\n",
    "              (y, self.indexes)))\n",
    "                \n",
    "        return y,\n",
    "\n",
    "\n",
    "    def backward_gpu(self, x, gy):\n",
    "        if self._used_cudnn:\n",
    "            return super(KMaxPooling1D, self).backward_gpu(x, gy)\n",
    "\n",
    "        n, c = self._in_shape[:2]\n",
    "        dims = self._in_shape[2:]\n",
    "        ys = gy[0].shape[2:]\n",
    "        gx = cuda.cupy.empty(self._in_shape, self._in_dtype)\n",
    "\n",
    "        ndim = self.ndim\n",
    "        cuda.elementwise('raw T gy, raw S indexes, int32 d_0, int32 out_0',\n",
    "                         'T gx',\n",
    "                         '''operation:\n",
    "                            int c0  = i / (d_0);\n",
    "                            int x_0 = i % d_0;\n",
    "                            int out_x0_0 = 0;\n",
    "                            int out_x1_0 = out_0;\n",
    "                            T val = 0;\n",
    "                            for (int out_x_0 = out_x0_0; out_x_0 < out_x1_0; ++out_x_0) {\n",
    "                              int offset_0 = 1 * (out_x_0 + out_0 * c0);\n",
    "                              int kx = x_0;\n",
    "                              if (indexes[offset_0] == kx) {\n",
    "                                val = val + gy[offset_0];\n",
    "                              }\n",
    "                            }\n",
    "                            gx = val;\n",
    "                         ''',\n",
    "                         'k_max_pool_1d_bwd')(\n",
    "            gy[0].reduced_view(), self.indexes.reduced_view(),\n",
    "            *(dims + ys + (gx,)))\n",
    "        \n",
    "        return gx,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-11T14:01:11.803634Z",
     "start_time": "2018-01-11T14:01:11.800289Z"
    }
   },
   "outputs": [],
   "source": [
    "def k_max_pooling_1d(x, k):\n",
    "    ndim = len(x.shape[2:])\n",
    "    return KMaxPooling1D(ndim, k)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-11T14:01:12.750122Z",
     "start_time": "2018-01-11T14:01:12.735653Z"
    }
   },
   "outputs": [],
   "source": [
    "class BottleNeckA(chainer.Chain):\n",
    "\n",
    "    def __init__(self, in_size, ch_size):\n",
    "        initialW = initializers.HeNormal()\n",
    "        super(BottleNeckA, self).__init__(\n",
    "            conv1 = L.ConvolutionND(\n",
    "                1, in_size, ch_size, 3, 1, 1, initialW=initialW),\n",
    "            bn1 = L.BatchNormalization(ch_size),\n",
    "            conv2 = L.ConvolutionND(\n",
    "                1, ch_size, ch_size, 3, 1, 1, initialW=initialW),\n",
    "            bn2 = L.BatchNormalization(ch_size),\n",
    "            conv3 = L.ConvolutionND(\n",
    "                1, in_size, ch_size, 1, 1, 0,\n",
    "                initialW=initialW, nobias=True),\n",
    "            bn3 = L.BatchNormalization(ch_size)\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h1 = F.relu(self.bn1(self.conv1(x)))\n",
    "        h1 = self.bn2(self.conv2(h1))\n",
    "        h2 = self.bn3(self.conv3(x))\n",
    "\n",
    "        return F.relu(h1 + h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-11T14:01:13.454810Z",
     "start_time": "2018-01-11T14:01:13.443515Z"
    }
   },
   "outputs": [],
   "source": [
    "class BottleNeckB(chainer.Chain):\n",
    "\n",
    "    def __init__(self, ch_size):\n",
    "        initialW = initializers.HeNormal()\n",
    "        super(BottleNeckB, self).__init__(\n",
    "            conv1 = L.ConvolutionND(\n",
    "                1, ch_size, ch_size, 3, 1, 1, initialW=initialW),\n",
    "            bn1 = L.BatchNormalization(ch_size),\n",
    "            conv2 = L.ConvolutionND(\n",
    "                1, ch_size, ch_size, 3, 1, 1, initialW=initialW),\n",
    "            bn2 = L.BatchNormalization(ch_size)\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = F.relu(self.bn1(self.conv1(x)))\n",
    "        h = self.bn2(self.conv2(h))\n",
    "\n",
    "        return F.relu(h + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-11T14:01:13.961700Z",
     "start_time": "2018-01-11T14:01:13.951394Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvBlock(chainer.ChainList):\n",
    "    \n",
    "    def __init__(self, layer, in_size, ch_size):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        if in_size != ch_size:\n",
    "            self.add_link(BottleNeckA(in_size, ch_size))\n",
    "        else:\n",
    "            self.add_link(BottleNeckB(ch_size))\n",
    "\n",
    "        for i in range(layer - 1):\n",
    "            self.add_link(BottleNeckB(ch_size))\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        for f in self.children():\n",
    "            x = f(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-11T14:01:15.353242Z",
     "start_time": "2018-01-11T14:01:15.313096Z"
    }
   },
   "outputs": [],
   "source": [
    "class VDCNN(chainer.Chain):\n",
    "    \n",
    "    def __init__(self, n_out):\n",
    "        super(VDCNN, self).__init__(\n",
    "            embed1 = L.EmbedID(3017, 50, initialW=initializers.HeUniform(), ignore_label=-1),\n",
    "            conv1 = L.ConvolutionND(1, 50, 64, 3, 1, 1, initialW=initializers.HeNormal()),\n",
    "            res2 = ConvBlock(2, 64, 64),\n",
    "            res3 = ConvBlock(2, 64, 128),\n",
    "            res4 = ConvBlock(2, 128, 256),\n",
    "            res5 = ConvBlock(2, 256, 512),\n",
    "            fc6 = L.Linear(4096, 2048),\n",
    "            fc7 = L.Linear(2048, 2048),\n",
    "            fc8 = L.Linear(2048, n_out)\n",
    "        )\n",
    "    \n",
    "    def __call__(self, x, t):\n",
    "        h = self.embed1(x)\n",
    "        h = h.transpose(0,2,1)\n",
    "        h = self.conv1(h)\n",
    "        h = self.res2(h)\n",
    "        h = F.max_pooling_nd(h, 3, 2, 1, cover_all=False)\n",
    "        h = self.res3(h)\n",
    "        h = F.max_pooling_nd(h, 3, 2, 1, cover_all=False)\n",
    "        h = self.res4(h)\n",
    "        h = F.max_pooling_nd(h, 3, 2, 1, cover_all=False)\n",
    "        h = self.res5(h)\n",
    "        h = k_max_pooling_1d(h, 8)\n",
    "        h = F.relu(self.fc6(h))\n",
    "        h = F.relu(self.fc7(h))\n",
    "        h = self.fc8(h)\n",
    "        \n",
    "        if t is not None:\n",
    "            loss = F.softmax_cross_entropy(h, t)\n",
    "            chainer.report({'loss': loss, 'accuracy': F.accuracy(h, t)}, self)\n",
    "            return loss\n",
    "        else:\n",
    "            return to_cpu(F.softmax(h).data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-08T08:26:58.680294Z",
     "start_time": "2018-01-08T08:26:52.881452Z"
    }
   },
   "outputs": [],
   "source": [
    "_labels = []\n",
    "_sentences = []\n",
    "text_file = open('./data/afpbb-id.txt')\n",
    "line = text_file.readline()\n",
    "len_sentence = 0\n",
    "while line:\n",
    "    label, sentence = line[0], line.split(' ')[1:-1]\n",
    "    id_sentence = np.ones(1024, dtype=np.float32) * (-1)\n",
    "    len_sentence += len(sentence)\n",
    "    for i, c in enumerate(sentence):\n",
    "        id_sentence[i] = c\n",
    "    _labels.append(label)\n",
    "    _sentences.append(id_sentence)\n",
    "    line = text_file.readline()\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-08T08:26:58.750499Z",
     "start_time": "2018-01-08T08:26:58.699524Z"
    }
   },
   "outputs": [],
   "source": [
    "_sentences = np.array(_sentences, dtype=np.int32)\n",
    "_labels = np.array(_labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-08T08:26:58.753545Z",
     "start_time": "2018-01-08T08:26:58.751443Z"
    }
   },
   "outputs": [],
   "source": [
    "_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-08T08:26:58.758711Z",
     "start_time": "2018-01-08T08:26:58.754466Z"
    }
   },
   "outputs": [],
   "source": [
    "from chainer.datasets import TupleDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-08T08:26:58.788638Z",
     "start_time": "2018-01-08T08:26:58.759578Z"
    }
   },
   "outputs": [],
   "source": [
    "is_test = np.arange(len(_labels)) % 10 == 0\n",
    "\n",
    "train = TupleDataset(_sentences[~is_test], _labels[~is_test])\n",
    "\n",
    "test = TupleDataset(_sentences[is_test], _labels[is_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-08T08:26:58.791900Z",
     "start_time": "2018-01-08T08:26:58.789809Z"
    }
   },
   "outputs": [],
   "source": [
    "del _sentences\n",
    "del _labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-08T08:26:59.384972Z",
     "start_time": "2018-01-08T08:26:58.792759Z"
    }
   },
   "outputs": [],
   "source": [
    "model = VDCNN(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-08T08:26:59.387808Z",
     "start_time": "2018-01-08T08:26:59.386125Z"
    }
   },
   "outputs": [],
   "source": [
    "from chainer import training\n",
    "from chainer.training import extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-08T10:52:25.497466Z",
     "start_time": "2018-01-08T08:26:59.388727Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_iter = chainer.iterators.MultiprocessIterator(train, batch_size=50)\n",
    "test_iter = chainer.iterators.MultiprocessIterator(test, batch_size=50, repeat=False)\n",
    "\n",
    "optimizer = chainer.optimizers.MomentumSGD()\n",
    "optimizer.setup(model)\n",
    "optimizer.add_hook(chainer.optimizer.GradientClipping(5.0))\n",
    "\n",
    "updater = training.StandardUpdater(train_iter, optimizer, device=0)\n",
    "trainer = training.Trainer(updater, (30, 'epoch'), out='result/afpbb-30epoch')\n",
    "\n",
    "class TestModeEvaluator(extensions.Evaluator):\n",
    "    def evaluate(self):\n",
    "        model = self.get_target('main')\n",
    "        with chainer.using_config('train', False):\n",
    "            ret = super(TestModeEvaluator, self).evaluate()\n",
    "        return ret\n",
    "\n",
    "trainer.extend(TestModeEvaluator(test_iter, model, device=0), trigger=(1, 'epoch'))\n",
    "trainer.extend(extensions.dump_graph('main/loss'))\n",
    "\n",
    "trainer.extend(extensions.LogReport(trigger=(1, 'epoch')))\n",
    "\n",
    "trainer.extend(extensions.PrintReport(['epoch', 'iteration', 'main/accuracy', 'validation/main/accuracy', 'elapsed_time']\n",
    "                                     ), trigger=(1, 'epoch'))\n",
    "\n",
    "trainer.extend(extensions.ProgressBar(update_interval=30))\n",
    "\n",
    "trainer.extend(extensions.ExponentialShift('lr', 0.5), trigger=(3, 'epoch'))\n",
    "\n",
    "print('running')\n",
    "\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-08T11:25:19.041495Z",
     "start_time": "2018-01-08T11:25:19.039868Z"
    }
   },
   "outputs": [],
   "source": [
    "from chainer import serializers\n",
    "serializers.save_npz('./models/afpbb-epoch30.npz', model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
